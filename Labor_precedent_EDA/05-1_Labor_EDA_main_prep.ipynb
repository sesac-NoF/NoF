{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분할 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 처리 및 분석\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 문자\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\user\\Desktop\\프로젝트 기획서\\SeSac-2024\\data_file\\Labor_datacombined.csv', encoding='utf-8')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 한글 깨짐 방지\n",
    "plt.rcParams['font.family'] = \"Malgun Gothic\"\n",
    "\n",
    "# 마이너스 깨짐 방지\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '근로' 만 추출 , 전체 데이터 중 5000개만 사용\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 예시로 df 데이터프레임을 생성합니다. 실제로는 이미 존재하는 df를 사용하세요.\n",
    "# df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# '근로' 단어가 포함된 행 필터링\n",
    "df_labor = df.iloc[:10000][df['사건명'].str.contains('근로', na=False) | df['판례내용'].str.contains('근로', na=False)]\n",
    "\n",
    "# 결과 확인\n",
    "print(df_labor.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분석 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 처리 및 분석\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 문자\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 한글 깨짐 방지\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfont.family\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMalgun Gothic\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 마이너스 깨짐 방지\u001b[39;00m\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.unicode_minus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 한글 깨짐 방지\n",
    "plt.rcParams['font.family'] = \"Malgun Gothic\"\n",
    "\n",
    "# 마이너스 깨짐 방지\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '근로' 만 추출 , 전체 데이터 중 5000개만 사용\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 예시로 df 데이터프레임을 생성합니다. 실제로는 이미 존재하는 df를 사용하세요.\n",
    "# df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# '근로' 단어가 포함된 행 필터링\n",
    "df_labor = df.iloc[:10000][df['사건명'].str.contains('근로', na=False) | df['판례내용'].str.contains('근로', na=False)]\n",
    "\n",
    "# 결과 확인\n",
    "print(df_labor.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 전처리(완) -> 형태소 분석 -> 불용어 제거 -> 명사추출 -> 주제모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "형태소 분석, 불용어제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re  # 정규 표현식 모듈\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# 불용어 파일 로드\n",
    "stopwords_file_path = r'C:\\Users\\user\\Desktop\\프로젝트 기획서\\SeSac-2024\\data_file\\sorted_words.txt'\n",
    "stopwords_pick = ['제', '호로', '등', '것', '항', '의', '금','검사','판결','거나', '유1', '상고이유', '기초', '사실', '기초사실','사고','피고','원고','피고인','사건','담당','변호사','변호인','변론','종결','소외']\n",
    "pattern = r'제\\d+|\\d호증|\\d호'   # 정규 표현식 패턴\n",
    "\n",
    "# 불용어 파일을 읽어 불용어 목록 생성\n",
    "with open(stopwords_file_path, 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(f.read().splitlines())\n",
    "\n",
    "# 불용어 제거 함수 (리스트 상태로 처리)\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_words = [\n",
    "        word for word in tokens \n",
    "        if len(word) > 1 \n",
    "        and word not in stopwords \n",
    "        and not word.isdigit()  # 숫자인 경우 제외\n",
    "        and word not in stopwords_pick \n",
    "        and not re.match(pattern, word)\n",
    "    ]\n",
    "    return ' '.join(filtered_words)  # 문자열로 반환 / 리스트로 변환하지 말 것\n",
    "\n",
    "# 불용어 제거 수행\n",
    "df_labor['정제_판례내용'] = df_labor['형태소_토큰'].apply(remove_stopwords)\n",
    "\n",
    "# 결과 확인\n",
    "print(df_labor['정제_판례내용'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "명사추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "# 명사 추출 함수\n",
    "def extract_nouns(text):\n",
    "    nouns = okt.nouns(text)  # 텍스트에서 명사 추출\n",
    "    return nouns  # 명사 리스트 반환\n",
    "\n",
    "# 정제된 판례 내용에서 명사 추출 수행\n",
    "df_labor['명사_추출'] = df_labor['정제_판례내용'].apply(extract_nouns)\n",
    "\n",
    "df_labor['명사_추출']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명사별 빈도 확인\n",
    "\n",
    "# Okt 객체 생성\n",
    "okt = Okt()\n",
    "\n",
    "# 명사 추출 함수\n",
    "def extract_nouns(text):\n",
    "    nouns = okt.nouns(text)  # 텍스트에서 명사 추출\n",
    "    return nouns  # 명사 리스트 반환\n",
    "\n",
    "# 모든 명사 추출 (리스트 평탄화)\n",
    "all_nouns = [noun for sublist in df_labor['명사_추출'] for noun in sublist]\n",
    "\n",
    "# 단어 빈도 계산\n",
    "word_freq = Counter(all_nouns)\n",
    "\n",
    "# 결과를 데이터프레임으로 변환\n",
    "freq_df = pd.DataFrame(word_freq.items(), columns=['단어', '빈도']).sort_values(by='빈도', ascending=False)\n",
    "\n",
    "# 결과 확인\n",
    "print(freq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 100개 단어 빈도 출력\n",
    "top_100_freq = freq_df.head(100)\n",
    "\n",
    "# 결과 확인\n",
    "print(top_100_freq)\n",
    "\n",
    "#freq_df.iloc[0:100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주제모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명사 추출 함수\n",
    "def extract_nouns(text):\n",
    "    nouns = okt.nouns(text)  # 텍스트에서 명사 추출\n",
    "    return ' '.join(nouns)  # 리스트를 공백으로 구분된 문자열로 반환\n",
    "\n",
    "# 정제된 판례 내용에서 명사 추출 수행\n",
    "df_labor['명사_추출2'] = df_labor['정제_판례내용'].apply(extract_nouns)\n",
    "\n",
    "# LDA를 위한 Count Vectorization\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# 결측치가 있는 경우 빈 문자열로 처리\n",
    "count_data = count_vectorizer.fit_transform(df_labor['명사_추출2'].str.lower())\n",
    "\n",
    "# LDA 모델 생성\n",
    "num_topics = 5  # 주제 개수 설정\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda.fit(count_data)\n",
    "\n",
    "# 주제 확인\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    print(f\"주제 {idx}: \", end='')\n",
    "    # 각 주제에서 가장 높은 확률을 가진 단어 5개 출력\n",
    "    print([count_vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-5:]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
