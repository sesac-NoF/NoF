{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터프레임을 효율적으로 다루기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 프로세스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 데이터 로드 및 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('your_data.csv')\n",
    "print(df.head())\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치 처리: 결측치를 확인하고 적절히 처리합니다 (제거 또는 대체).\n",
    "텍스트 정제: 텍스트 데이터에서 불필요한 문자를 제거하고, 소문자 변환, 불용어 제거 등을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df['text_column'] = df['text_column'].str.replace('[^\\w\\s]', '').str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 텍스트 전처리 및 피처 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰화: 각 문장을 단어로 나누는 작업입니다.\n",
    "TF-IDF 벡터화: scikit-learn의 TfidfVectorizer를 사용하여 문서를 벡터화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(df['text_column'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 EDA(탐색적 데이터 분석)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 분포, 클래스 분포, 상관관계 등을 시각화합니다. seaborn이나 matplotlib를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 모델 학습 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터와 테스트 데이터 분할: train_test_split 함수를 사용하여 데이터를 나눕니다.\n",
    "모델 선택 및 훈련: 머신러닝 모델을 선택하여 훈련합니다. 예를 들어, 랜덤 포레스트, SVM, LSTM 등을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['target_variable'], test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 추가 팁"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 라이브러리 제시\n",
    "pandas: 데이터 로드 및 조작.\n",
    "numpy: 수치 계산 및 배열 연산.\n",
    "scikit-learn: 머신러닝 모델 훈련 및 평가.\n",
    "nltk / spaCy: 텍스트 전처리, 토큰화, 불용어 제거.\n",
    "TQDM: 진행 상황 표시.\n",
    "seaborn / matplotlib: 데이터 시각화.\n",
    "TensorFlow / Keras: 딥러닝 모델을 사용할 경우."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 데이터 타입 조정\n",
    "데이터프레임의 데이터 타입을 적절하게 조정하면 메모리 사용량을 줄일 수 있습니다. 일반적으로 사용되는 데이터 타입은 다음과 같습니다:\n",
    "\n",
    "정수형(int): 기본적으로 64비트로 설정되어 있지만, 데이터에 따라 8비트, 16비트, 32비트로 변경할 수 있습니다.\n",
    "부동소수점(float): 64비트 대신 32비트로 변경하여 메모리를 줄일 수 있습니다.\n",
    "문자열(object): Pandas에서 문자열은 기본적으로 object 타입으로 저장되며, 필요에 따라 category 타입으로 변환할 수 있습니다. 이는 메모리 사용을 줄이는 데 도움이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터프레임 로드\n",
    "df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# 메모리 사용 전 확인\n",
    "print(df.info(memory_usage='deep'))\n",
    "\n",
    "# 데이터 타입 변경\n",
    "df['int_column'] = df['int_column'].astype('int32')  # 정수형 32비트로 변경\n",
    "df['float_column'] = df['float_column'].astype('float32')  # 부동소수점 32비트로 변경\n",
    "df['category_column'] = df['category_column'].astype('category')  # 범주형으로 변경\n",
    "\n",
    "# 메모리 사용 후 확인\n",
    "print(df.info(memory_usage='deep'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 병렬 처리\n",
    "병렬 처리를 통해 대규모 데이터셋을 더 빠르게 처리할 수 있습니다. Python에서 병렬 처리를 수행하는 몇 가지 방법은 다음과 같습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Dask 데이터프레임 로드\n",
    "ddf = dd.read_csv('your_data.csv')\n",
    "\n",
    "# 연산 수행 (Dask는 실제 계산을 지연시킵니다)\n",
    "result = ddf.groupby('category_column').size().compute()  # 계산 실행\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
